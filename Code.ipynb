{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99df01f9",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7b7f5",
   "metadata": {},
   "source": [
    "https://www.pymc.io/projects/docs/en/latest/learn/core_notebooks/pymc_overview.html\n",
    "\n",
    "https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment/data?select=Tweets.csv\n",
    "\n",
    "https://success.appen.com/hc/en-us/articles/202703305-Getting-Started-Glossary-of-Terms#unit\n",
    "\n",
    "https://www.geeksforgeeks.org/role-of-log-odds-in-logistic-regression/\n",
    "\n",
    "https://www.pymc.io/projects/docs/en/v3/pymc-examples/examples/getting_started.html\n",
    "\n",
    "https://www.stat.cmu.edu/~brian/463-663/week10/Chapter%2009.pdf\n",
    "\n",
    "https://www.youtube.com/watch?v=pbcxb9xpTBI&ab_channel=PyData\n",
    "\n",
    "https://link.springer.com/article/10.1007/s00180-022-01287-4#:~:text=Bayesian%20multilevel%20(or%20hierarchical)%20logistic,values%20of%201%20or%200).\n",
    "\n",
    "https://www.pymc.io/projects/docs/en/v3.11.4/pymc-examples/examples/generalized_linear_models/GLM-logistic.html\n",
    "\n",
    "https://www.pymc.io/projects/docs/en/v3/pymc-examples/examples/case_studies/multilevel_modeling.html\n",
    "\n",
    "https://www.pymc.io/projects/examples/en/latest/mixture_models/dirichlet_mixture_of_multinomials.html#multinomial-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a1035",
   "metadata": {},
   "source": [
    "### Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.io as pio\n",
    "pyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#003f5c', '#2d6187', '#4b7db2', '#6796dd', '#84afed',\n",
    "           '#006d44', '#008b5c', '#00a970', '#00c87f', '#00e78c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f59f8c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e070f",
   "metadata": {},
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca5498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = len(df)\n",
    "cols = len(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc71b1",
   "metadata": {},
   "source": [
    "The data set is called  'Twitter US Airline Sentiment' and has 14 640 rows and 15 columns. Each row represents a \"tweet\" with information about the user and the sentiment of the \"tweet\" along with the original text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315bc0f",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fe96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.concat([df.isna().sum(),(df.isna().sum() / rows)*100],axis=1).round(2)\n",
    "missing.columns = ['Number of missing values','Percentage']\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3807f2",
   "metadata": {},
   "source": [
    "The data set has a large number of missing values in some of the columns. If we look at the feature *negativereason*, it is clear that it is supposed to have missing values since it will only be non-null if the tweet was was marked with 'negative' sentiment. \n",
    "Before discarding any features with missing values, it is interesting to look at what the reasons were for 'negative' tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7403d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = df[~df['negativereason'].isna()]\n",
    "counts = df_neg.groupby(['negativereason']).size().reset_index(name='Count')\n",
    "\n",
    "fig = px.bar(counts, \n",
    "             x='negativereason', \n",
    "             y='Count', \n",
    "             color='negativereason',\n",
    "             labels={'negativereason': 'Sentiment', 'Count': 'Occurrences'},\n",
    "             barmode='group',\n",
    "             color_discrete_sequence=palette)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='',\n",
    "    xaxis_title='Negative Reason',\n",
    "    yaxis_title='Number of tweets',\n",
    "    legend_title_text='',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5f9dc",
   "metadata": {},
   "source": [
    "It is clear that the main reasons for having a bad flight experience is due to customer service issues and delayed flights. \n",
    "\n",
    "Next we will drop all columns that had more than 25% missing values and we are left with only 8 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 25\n",
    "df_new = df.dropna(axis=1, thresh=int(df.shape[0] * (1 - threshold / 100)))\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be200c67",
   "metadata": {},
   "source": [
    "Focusing on the *airline_sentiment* column, we can see that more than 60% of tweets in the data set were of a negative sentiment, followed by 21% neutral and 16% positive. The confidence score for all three sentiment classes were high with negative tweets confidence score the highest at 93%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e958619",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = df_new.groupby(['airline_sentiment']).size().reset_index(name='Count')\n",
    "\n",
    "sentiment_totals = pd.concat([sentiment_counts,(sentiment_counts['Count'] / rows)*100],axis=1).round(2)\n",
    "sentiment_totals.columns = ['airline_sentiment','Count','Percentage of tweets']\n",
    "\n",
    "avg_conf = df_new.groupby('airline_sentiment')['airline_sentiment_confidence'].mean()\n",
    "\n",
    "sentiment_totals['Mean confidence'] = avg_conf.values\n",
    "\n",
    "sentiment_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(sentiment_counts, \n",
    "             x='airline_sentiment', \n",
    "             y='Count', color='airline_sentiment',\n",
    "             labels={'airline_sentiment': 'Sentiment', 'Count': 'Occurrences'},\n",
    "             barmode='group',\n",
    "             color_discrete_sequence=palette)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='',\n",
    "    xaxis_title='Sentiment',\n",
    "    yaxis_title='Number of tweets',\n",
    "    legend_title_text='',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5f51e",
   "metadata": {},
   "source": [
    "Tweets include sentiment on six different airlines. Most tweets were about United airlines followed by US Airways and American airlines. Looking at the bar chart it is interesting to note that Virgin America airlines had approximately the same number of neutral, positive, and negative tweets whereas the top three airlines had a large proportion of negative tweets compared to neutral and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_new['airline_sentiment'], df_new['airline'],margins=True)\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0216ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = df_new.groupby(['airline', 'airline_sentiment']).size().unstack().reindex(df_new['airline'].unique()).fillna(0)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, group in enumerate(group_counts.columns):\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=group_counts.index,\n",
    "        y=group_counts[group],\n",
    "        name=group,\n",
    "        marker=dict(color=palette[i % len(palette)])\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='',\n",
    "    xaxis_title='Airline',\n",
    "    yaxis_title='Number of tweets',\n",
    "    barmode='group',\n",
    "    showlegend=True,\n",
    "    bargap=0.1\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65f071",
   "metadata": {},
   "source": [
    "Each tweet has a timestamp at which it was created. It does not seem like time of the day has an effect on the sentiment of the tweet. Looking at the bar chart we can see that all tweet sentiments have the same trend with more tweets being made in the day time than night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a774739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[:,'hour_of_day'] = pd.to_datetime(df_new['tweet_created']).dt.hour\n",
    "\n",
    "grouped = df_new.groupby(['hour_of_day', 'airline_sentiment']).size().reset_index(name='count')\n",
    "\n",
    "traces = []\n",
    "for i, sentiment in enumerate(grouped['airline_sentiment'].unique()):\n",
    "    sentiment_data = grouped[grouped['airline_sentiment'] == sentiment]\n",
    "    trace = go.Scatter(\n",
    "        x=sentiment_data['hour_of_day'],\n",
    "        y=sentiment_data['count'],\n",
    "        mode='lines+markers',\n",
    "        name=sentiment,\n",
    "        line=dict(color=palette[i % len(palette)]),\n",
    "        marker=dict(color=palette[i % len(palette)])\n",
    "    )\n",
    "    traces.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='',\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(title='Number of tweets')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab2bd9",
   "metadata": {},
   "source": [
    "## Model specification and fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9ff2d",
   "metadata": {},
   "source": [
    "https://online.stat.psu.edu/stat504/book/export/html/667#:~:text=The%20multinomial%20distribution%20arises%20from,%3D%201%20%2C%20%E2%80%A6%20%2C%20k%20.\n",
    "\n",
    "It is difficult to know the exact sentiment of tweets made by humans as sentiment cannot be easily inferred from text. One would think that most people do not have the best experience with airlines and we can use this as *prior* knowledge for our model. We are trying to estimate the posterior probabilities of the *airline_sentiment* variable that has three classes. Since the variable has categorical outcome with more than two classes, we can use the Multinomial distribution to model the posterior probabilities and the priors from a Dirichlet distribution.\n",
    "\n",
    "The Multinomial Distribution can be described as the following:\n",
    "We have $n$ number of trails and each trail has $k$ mutually exclusive outcomes say $E_1, E_2, ..., E_k$. Each outcome $E_j$ can occur with probability $\\pi_j, j = 1,2,..., k$.\n",
    "Let $X_j$ be the count of the number of trials with outcome $E_j$, so $X = (X_1, X_2, ..., X_k)$ is a random vector with a multinomial distribution:\n",
    "$X$ ~ $Mult(n,\\pi)$, with $n$ the number of trails and parameter vector $\\pi = (\\pi_1, \\pi_2, ..., \\pi_k)$.\n",
    "\n",
    "Referring to the Twitter US Airline Sentiment data we can say that we have $n = 14640$ tweets as our number of trails and we have three different sentiment outcomes, $E_1 = neutral, E_2 = positive, E_3 = negative$. The probability of each outcome is denote by the vector $\\pi = (0.212, 0.161, 0.627)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49c3b9",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e728bb",
   "metadata": {},
   "source": [
    "First we try a simple model that tries to estimate the posterior probabilities with the Multinomial distribution and we specifiy strong priors for the airline sentiments that follow a Dirichlet distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['airline_sentiment'] = pd.factorize(df['airline_sentiment'])[0]\n",
    "group_counts = df.groupby(['airline_sentiment']).size()\n",
    "\n",
    "N = rows\n",
    "priors = [2.0, 1.0, 5.0]\n",
    "\n",
    "observed_counts = group_counts.values\n",
    "\n",
    "num_sentiments = len(df['airline_sentiment'].unique())\n",
    "\n",
    "with pm.Model() as simple_model:\n",
    "    probs = pm.Dirichlet(name='pi', a=priors, shape=num_sentiments)\n",
    "    \n",
    "    multinomial_dist = pm.Multinomial('sentiment', n=N, p=probs, observed=observed_counts)\n",
    "    \n",
    "pm.model_to_graphviz(simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78d98b",
   "metadata": {},
   "source": [
    "Next we simulate data from the model and check the parameter summary table. We can see that the mean value for each posterior probability is exactly equal to the proportions in the observed data. The 94% highest density interval is very narrow so that means we are fairly confident that the true proportions lies within this range. The Gelman-Rubin statistic, or $\\hat{R}$, is a measure of convergence for the simulated chains. An $\\hat{R}$ value equal to one is ideal since it suggests convergence. When looking at the trace plots below, it is clear that the parameters and its posteriors are moving together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623432c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with simple_model:\n",
    "    samples = pm.sample(1000, tune=1000, target_accept=0.99)\n",
    "    \n",
    "summary = pm.summary(samples)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c62285",
   "metadata": {},
   "source": [
    "### Modified Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2d329",
   "metadata": {},
   "source": [
    "Next we try a modified model that tries to estimate the posterior probabilities with the Multinomial distribution but we incorporate the *airline_sentiment_confidence* to estimate the posterior probabilities. Again we specifiy strong priors for the airline sentiments that follow a Dirichlet distribution and here the airline confidence score can take on values between 0 and 1 so it follows a Uniform distribution. We calculate the log-odds ratio of the sentiment probabilties and transform it to normalized probabilities using the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['airline_sentiment'] = pd.factorize(df['airline_sentiment'])[0]\n",
    "group_counts = df.groupby(['airline_sentiment']).size()\n",
    "\n",
    "N = rows\n",
    "priors = [2.0, 1.0, 5.0]\n",
    "\n",
    "observed_counts = group_counts.values\n",
    "\n",
    "num_sentiments = len(df['airline_sentiment'].unique())\n",
    "\n",
    "with pm.Model() as modified_model:\n",
    "    \n",
    "    probs = pm.Dirichlet(name='pi',a=priors,shape=num_sentiments)\n",
    "    sentiment_conf = pm.Uniform('sentiment_conf', lower=0, upper=1)\n",
    "    \n",
    "    logits = pm.Deterministic('logits', pm.math.dot(sentiment_conf, probs.T))\n",
    "\n",
    "    final_probs = pm.Deterministic('final_pi', pm.math.softmax(logits))\n",
    "\n",
    "    multinomial_dist = pm.Multinomial('sentiment', n=N, p=final_probs,observed=observed_counts)\n",
    "      \n",
    "pm.model_to_graphviz(modified_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea983de",
   "metadata": {},
   "source": [
    "Next we simulate data from the model and check the parameter summary table. We can see that the mean value for each posterior probability is close to the proportions in the observed data. The 94% highest density interval is also very narrow so that means we are fairly confident that the true proportions lies within this range. The $\\hat{R}$, values are again all equal to one which suggests that the chains have converged. When looking at the trace plots below, it is clear that the parameters and its posteriors are moving together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with modified_model:\n",
    "    samples = pm.sample(1000, tune=1000, target_accept=0.99)\n",
    "    \n",
    "summary = pm.summary(samples)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc9edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
